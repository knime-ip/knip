{"class":"classes.org.knime.knip.features.node.ui.FeatureCalculatorSwingInputHarvester","values":{"priority":-10000.0,"type":"org.scijava.module.process.PreprocessorPlugin"}}{"class":"classes.org.knime.knip.features.sets.ImageMomentFeatureSet","values":{"description":"<h1> Image Moments </h1> In image processing, computer vision and related fields, an image moment is a certain particular weighted average (moment) of the image pixels' intensities, or a function of such moments, usually chosen to have some attractive property or interpretation. </br>Image moments are useful to describe objects after segmentation. Simple properties of the image which are found via image moments include area (or total intensity), its centroid, and information about its orientation. There are four kind of image moments supported by this feature set <ul> \u0009<li>Raw Moments</li> \u0009<li> Central Moments</li> \u0009<li> Normalized Central Moments</li> \u0009<li>Hu Moments</li> </ul> For more information see <a href=\"https://en.wikipedia.org/wiki/Image_moment\">Image moment</a>","label":"Image Moments","type":"org.knime.knip.features.sets.FeatureSet"}}{"class":"classes.org.knime.knip.features.sets.HistogramFeatureSet","values":{"description":"<h1> Histogram Feature Set</h1> <h2> Description</h2> Distributes the pixels into bins depending on their pixel values and counts the numbers of pixels per bin.<h2>Parameters</h2> <ul><li><strong>Number of Bins:</strong> The number of bins of the histogram</li></ul>","label":"Histogram Features","type":"org.knime.knip.features.sets.FeatureSet"}}{"class":"classes.org.knime.knip.features.sets.Geometric2DFeatureSet","values":{"description":"<h1> Geometric 2D Feature Set</h1> <h2>Description</h2> Calculates different shape descriptors on the given input. Some examples include <ul><li><strong>Perimeter:</strong> The length of the outside boundary of the input.</li><li><strong>Size:</strong> The area of the input.</li><li><strong>Circularity:</strong> The circularity of the input.</li> <li><strong>...</strong></li></ul> For some more examples and descriptions see the <a href=\"http://rsbweb.nih.gov/ij/docs/guide/146-30.html#sub:Set-Measurements...\"> ImageJ User Guide </a>","label":"Geometric Features 2D","type":"org.knime.knip.features.sets.FeatureSet"}}{"class":"classes.org.knime.knip.features.sets.Haralick2DFeatureSet","values":{"description":"<h1> Haralick 2D Feature Set</h1> <h2>Description</h2> The basis for these features is the gray-level co-occurrence matrix. This matrix is square with dimension Ng, where Ng is the number of gray levels in the image. Element [i,j] of the matrix is generated by counting the number of times a pixel with value i is adjacent to a pixel with value j and then dividing the entire matrix by the total number of such comparisons made. Each entry is therefore considered to be the probability that a pixel with value i will be found adjacent to a pixel of value j. For more information see <a href=\"http://murphylab.web.cmu.edu/publications/boland/boland_node26.html\">Haralick Features</a><h2>Parameters</h2> <ul><li><strong>Num. Grey Levels:</strong> The number of grey values determines the size of the co-occurence matrix on which the Haralick features are calculated.</li><li><strong>Distance:</strong> The maximum distance between pairs of pixels which will be added to the co-occurence matrix.</li><li><strong>Orientation:</strong> Orientation of the pairs of pixels which will be added to the co-occurence matrix.</li></ul>","label":"Haralick 2D Features","type":"org.knime.knip.features.sets.FeatureSet"}}{"class":"classes.org.knime.knip.features.sets.CenterOfGravityFeatureSet","values":{"description":"<h1> Center of Gravity Feature Set</h1> <h2>Description</h2> Calculates the center of gravity for each dimension of the given input.","label":"Center of Gravity","type":"org.knime.knip.features.sets.FeatureSet"}}{"class":"classes.org.knime.knip.features.sets.Geometric3DFeatureSet","values":{"description":"<h1> Geometric 3D Feature Set</h1> <h2>Description</h2> Calculates different shape descriptors on the given input. Some examples include <ul><li><strong>Perimeter:</strong> The length of the outside boundary of the input.</li><li><strong>Size:</strong> The volume of the input.</li><li><strong>Circularity:</strong> The circularity of the input.</li> <li><strong>...</strong></li></ul> For some more examples and descriptions see the <a href=\"http://rsbweb.nih.gov/ij/docs/guide/146-30.html#sub:Set-Measurements...\"> ImageJ User Guide </a>","label":"Geometric Features 3D","type":"org.knime.knip.features.sets.FeatureSet"}}{"class":"classes.org.knime.knip.features.sets.Haralick3DFeatureSet","values":{"description":"<h1> Haralick 3D Feature Set</h1> <h2>Description</h2> The basis for these features is the gray-level co-occurrence matrix. This matrix is square with dimension Ng, where Ng is the number of gray levels in the image. Element [i,j] of the matrix is generated by counting the number of times a pixel with value i is adjacent to a pixel with value j and then dividing the entire matrix by the total number of such comparisons made. Each entry is therefore considered to be the probability that a pixel with value i will be found adjacent to a pixel of value j. For more information see <a href=\"http://murphylab.web.cmu.edu/publications/boland/boland_node26.html\">Haralick Features</a><h2>Parameters</h2> <ul><li><strong>Num. Grey Levels:</strong> The number of grey values determines the size of the co-occurence matrix on which the Haralick features are calculated.</li><li><strong>Distance:</strong> The maximum distance between pairs of pixels which will be added to the co-occurence matrix.</li><li><strong>Orientation:</strong> Orientation of the pairs of pixels which will be added to the co-occurence matrix.</li></ul>","label":"Haralick 3D Features","type":"org.knime.knip.features.sets.FeatureSet"}}{"class":"classes.org.knime.knip.features.sets.optimizedfeatures.OptimizedMin","values":{"label":"Statistics: Min","priority":Infinity,"type":"net.imagej.ops.Ops$Stats$Min"}}{"class":"classes.org.knime.knip.features.sets.optimizedfeatures.OptimizedMax","values":{"label":"Statistics: Max","priority":Infinity,"type":"net.imagej.ops.Ops$Stats$Max"}}{"class":"classes.org.knime.knip.features.sets.StatsFeatureSet","values":{"description":"<h1> Statistic Features </h1> Feature Set of statistical measurements of the image. Some examples include: <ul> <li> <strong>Minimum</strong>: The minimum pixel value of the image</li> <li> <strong>Maximum</strong>: The maximum pixel value of the image</li> <li> <strong>Variance</strong>: The variance of the  pixel values of the image</li> <li> ... </li> </ul> For more examples and information see the <a href=\"http://rsbweb.nih.gov/ij/docs/guide/146-30.html#sub:Set-Measurements...\"> ImageJ User Guide </a>","label":"Statistic Features","type":"org.knime.knip.features.sets.FeatureSet"}}{"class":"classes.org.knime.knip.features.sets.CentroidFeatureSet","values":{"description":"<h1> Centroid Feature Set</h1> <h2>Runs only on regions of labelings.</h2> <h2>Description</h2> Calculates the centroid of the given input.","label":"Centroid","type":"org.knime.knip.features.sets.FeatureSet"}}{"class":"classes.org.knime.knip.features.sets.LBP2DFeatureSet","values":{"description":"<h1> 2D Local Binary Pattern Feature Set</h1> <h2>Note: Runs only on single Images!</h2> <h2> Description</h2> Local binary patterns (LBP) is a type of feature used for classification in computer vision.. The LBP feature vector, in its simplest form, is created in the following manner: <ul> <li> For each pixel in a cell, compare the pixel to each of its 8 neighbors (on its left-top, left-middle, left-bottom, right-top, etc.). Follow the pixels along a circle, i.e. clockwise or counter-clockwise. </li> <li> Where the center pixel's value is greater than the neighbor's value, write \"1\". Otherwise, write \"0\". This gives an 8-digit binary number (which is usually converted to decimal for convenience).</li> <li> Compute the histogram, over the cell, of the frequency of each \"number\" occurring (i.e., each combination of which pixels are smaller and which are greater than the center).</li> </ul><h2>Parameters</h2> <ul><li><strong>Distance: </strong> Distance of the neighborhood pixels to the center pixel </li> <li><strong>Number of Bins: </strong> The number of bins of the histogram</li></ul> See <a href=\"https://en.wikipedia.org/wiki/Local_binary_patterns\"> Wikipedia</a> for more information.","label":"Local Binary Patterns 2D","type":"org.knime.knip.features.sets.FeatureSet"}}{"class":"classes.org.knime.knip.features.sets.Tamura2DFeatureSet","values":{"description":"<h1> Tamura Features </h1> <h2>Note: Runs only on single Images!</h2> <h2>Description</h2> Feature Set of the Tamura texture features. These features include: <ul> <li> <strong>Coarseness</strong> which relates to distances of notable spatial variations of grey levels, that is, implicitly, to the size of the primitive elements (texels) forming the texture. The proposed computational procedure accounts for differences between the average signals for the non-overlapping windows of different size:</li> <li> <strong>Contrast</strong> which measures how grey levels q; q = 0, 1, ..., qmax, vary in the image g and to what extent their distribution is biased to black or white. </li> <li> <strong>Directionality</strong> which is measured using the frequency distribution of oriented local edges against their directional angles.</li>  </ul> For more examples and information see the <a href=\"https://www.cs.auckland.ac.nz/courses/compsci708s1c/lectures/Glect-html/topic4c708FSC.htm#tamura\"> Tamura's Texture Features</a> <h2>Parameters</h2> <ul><li><strong>Histogram Size (Directionality):</strong> The size of the histogram used by the directionality feature.</li></ul>","label":"Tamura Features","type":"org.knime.knip.features.sets.FeatureSet"}}{"class":"classes.org.knime.knip.features.sets.StringToMatrixOrientation","values":{"type":"org.scijava.convert.Converter"}}{"class":"classes.org.knime.knip.features.sets.ZernikeFeatureSet","values":{"description":"<h1> Zernike Features </h1><h2> Description </h2> The Zernike polynomials were first proposed in 1934 by Zernike <a href=\"http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/SHUTLER3/node17.html#Zernike34\">[22]</a>. Their moment formulation appears to be one of the most popular, outperforming the alternatives <a href=\"http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/SHUTLER3/node17.html#Teh88\">[19]</a> (in terms of noise resilience, information redundancy and reconstruction capability). </br></br> For more information see <a href=\"http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/SHUTLER3/node11.html\"> Complex Zernike Moments </a> <h2> Parameters </h2> <ul>\u0009<li><strong>Minimum Order of Zernike Moment:</strong> The minimum order of the Zernike moments to be calculated. </li> \u0009<li><strong>Maximum Order of Zernike Moment:</strong>The maximum order of the Zernike moments to be calculated. </li></ul>","label":"Zernike Features","type":"org.knime.knip.features.sets.FeatureSet"}}{"class":"classes.org.knime.knip.features.LabelRegionToBitmaskConverter","values":{"type":"net.imagej.ops.Ops$Convert$Copy"}}{"class":"classes.org.knime.knip.features.DefaultFeatureService","values":{"type":"org.knime.knip.features.FeatureService"}}